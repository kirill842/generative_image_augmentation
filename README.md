# [Читать диплом](https://www.dropbox.com/scl/fi/8fvhxu0z3e09av9e7o2uz/2025-110508-_2.pdf?rlkey=9ukrmp6q3okqfvnuqkjqosctj&st=7fkuwf6z&dl=0) 

---

## About

**Generative Image Augmentation** — это Python-проект, реализующий метод расширения обучающих выборок изображений с помощью дообучения предобученной диффузионной модели Stable Diffusion 2 и техники Low-Rank Adaptation (LoRA). Основная цель — синтезировать изображения, соответствующие гладкому распределению исходной выборки, и автоматически разметить их для последующего обучения детекторов.

**Ключевые особенности:**

* **Дообучение Stable Diffusion 2.0 с LoRA**
  
  Использование скрипта `train_text_to_image_lora.py` (Diffusers) для эффективной адаптации предобученной модели под узкую предметную область с минимальными вычислительными затратами.
  
* **Генерация синтетических изображений**
  
  Набор python-скриптов, которые в совокупности составляют единый алгоритм генерации синтетических изображений с разметкой
  
* **Автоматическая разметка с использованием модели для детекции**
  
  Детектирование на сгенерированных изображениях с кастомным порогом по confidence score, чтобы отбирать только объекты, в детекции которых модель сильно уверена.
  
* **Модульность и расширяемость**
  
  Лёгкая замена модели генерации, меток и модели разметки под любые другие классы объектов.

## Quick Start

1. **Клонировать репозиторий**

   ```bash
   git clone https://github.com/kirill842/generative_image_augmentation.git
   cd generative_image_augmentation
   ```

2. **Установить зависимости**

   ```bash
   pip install -r requirements.txt
   ```

3. **Датасет**

   Необходимо сформировать папку с изображениями и папку с разметкой для детекции в формате YOLO. Имена файлов изображений должны соответствовать именам файлом с разметкой. Датасет с изображениями и с разметкой должны иметь папки train, val и test.

4. **Подготовка изображений**

   ```bash
   python prepare_dataset_for_finetuning.py \
     --images_dir="<путь к изображениям>" \
     --labels_dir="<путь к меткам>" \
     --output_dir="<путь куда сохранять изображения>" \
     --crop_size=<размер входного изображения генеративной_модели> \
     --percent=<минимальный размер объекта относительно всего изображения, которую должен занимать объект чтобы изображение было сохранено> \
     --stride=<шаг вырезки объектов> \
     --text_label="<текстовый промпт, который сопоставить каждому изображению>"
   ```

5. **Дообучение модели**

   ```bash
   accelerate launch third_party/train_text_to_image_lora.py \
     --pretrained_model_name_or_path=<ссылка на предтренированную модель, например "stabilityai/stable-diffusion-2"> \
     --train_data_dir="<путь где лежат изображения для тренировки>" \
     --caption_column="text" --center_crop --resolution=<размер входного изображения генеративной модели> \
     --random_flip --train_batch_size=1 --num_train_epochs=<количество эпох тренировки> \
     --checkpointing_steps=<через сколько шагов оптимизации генерировать валидационную выборку> \
     --learning_rate=1e-04 --lr_scheduler="constant" \
     --lr_warmup_steps=0 --output_dir="<куда сохранить модель>" \
     --validation_prompt="<текстовая метка, которая была задана на прошлом шаге каждому изображению>" \
     --report_to="wandb" --num_validation_images=<количество генерируемых изображений для валидации>
   ```

6. **Генерация**

   ```bash
   python sd_sampling_after_finetuning_lora.py \
     --pretrained_model_name_or_path="<предобученная модель, например: "stabilityai/stable-diffusion-2">" \
     --lora_checkpoint_dir="<путь до сохраненной модели, обученной на прошлом шаге>" \
     --output_dir="<куда сохранять сгенерированные изображения>" \
     --prompt="<промпт для генерации>" \
     --device="<девайс для дообучения, например "cuda:0">" \
     --num_inference_steps=<количество шаго обратной диффузии, например 30> \
     --guidance_scale=<как сильно модели следовать промпту, например 7.5> \
     --num_images=<сколько изображений генерировать, например 10000>
   
   ```

7. **Разметка**

   ```bash
   python auto_labeling_with_img_transfer.py \
     --model_path="<путь к модели, например "yolov8.pt">" \
     --image_dir="<путь к сгенерированным изображениям>" \
     --label_out_dir="<путь к сохранению разметки>" \
     --image_out_dir="<путь к сохранению изображений>" \
     --conf_threshold=<порог фильтрации по степени уверенности модели в детекции> \
     --device="какой девайс использовать, например "cuda:0"" \
     --object_class_id=<какой объект детектировать моделью, например 14 - это класс птицы для yolov8> \
     --output_class_id=<какой id записать в выходной файл разметки, например 0> 
   ```

## Acknowledgements

- `train_text_to_image_lora.py` by [Original Author Name](https://github.com/author), 
  licensed under MIT. Source: https://github.com/author/repo.

